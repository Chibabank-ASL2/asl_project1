{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70aa1469-82a0-4879-b03a-c666dfb74cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-bigquery in /home/jupyter/.local/lib/python3.10/site-packages (3.21.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: google-cloud-storage in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.35.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.7.2)\n",
      "Requirement already satisfied: packaging>=20.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (24.1)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage) (1.6.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.65.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (3.20.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.66.1)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (4.9)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.21.0->google-cloud-bigquery) (2024.8.30)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-bigquery) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-bigquery pandas google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d280586-0d1e-4907-ade4-833da141ca61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.10/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "2b20c4cf-af19-4390-a29c-15acc89b34de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery import SchemaField\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911985e2-a226-4574-a81a-0e3ee224da49",
   "metadata": {},
   "source": [
    "## 定数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "12e0f835-ca59-4289-ba68-9ed0ae735b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"project-asl-chibabank\" \n",
    "DATASET_DIR = \"T02_デーブルデータ\"\n",
    "DESC_COL_DIR = \"Column_description\" \n",
    "\n",
    "PROJECT_ID = \"qwiklabs-asl-02-9dacbbe2194b\"\n",
    "DATASET_ID = \"ASL_dataset4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "bad4f5b9-91e3-477d-babb-66cac25b21b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_char_from_array(arr, char_to_remove, char_to_replace):\n",
    "    return [s.replace(char_to_remove, char_to_replace) for s in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "3ed4ca7f-4dbb-4b11-bd51-878943662e0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FILE_NAME_LIST = [\n",
    "    \"CIF別取引属性_個人_サンプル.xlsx\", \n",
    "    \"CRM_交渉履歴_サンプル.xlsx\", \n",
    "    \"VISAデビット契約情報_サンプル.xlsx\", \n",
    "    \"チャネル別利用状況_サンプル.xlsx\", \n",
    "    \"保険元帳_サンプル.xlsx\",\n",
    "    \"入払情報_日次_サンプル.xlsx\",\n",
    "    \"名寄せ取引属性_日次_サンプル.xlsx\",\n",
    "    \"完済融資バッチキー_サンプル.xlsx\",\n",
    "    \"定期預金元帳_サンプル.xlsx\",\n",
    "    \"為替取引明細_サンプル.xlsx\",\n",
    "    \"融資バッチキー_サンプル.xlsx\",\n",
    "    \"融資ローン元帳_サンプル.xlsx\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "5b369b9c-0962-44a7-94ea-fc0d70be9656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TABLE_ID_LIST = remove_char_from_array(FILE_NAME_LIST, \"_サンプル.xlsx\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "73bc6f70-97f1-4e9b-b1f3-831a939986cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DESC_COL_FILE_NAME_LIST = [\n",
    "    \"desc_col_CIF別取引属性_個人_サンプル.xlsx\",\n",
    "    \"desc_col_CRM_交渉履歴_サンプル.xlsx\", \n",
    "    \"desc_col_VISAデビット契約情報_サンプル.xlsx\", \n",
    "    \"desc_col_チャネル別利用状況_サンプル.xlsx\", \n",
    "    \"desc_col_保険元帳_サンプル.xlsx\",\n",
    "    \"desc_col_入払情報_日次_サンプル.xlsx\",\n",
    "    \"desc_col_名寄せ取引属性_日次_サンプル.xlsx\",\n",
    "    \"desc_col_完済融資バッチキー_サンプル.xlsx\",\n",
    "    \"desc_col_定期預金元帳_サンプル.xlsx\",\n",
    "    \"desc_col_為替取引明細_サンプル.xlsx\",\n",
    "    \"desc_col_融資バッチキー_サンプル.xlsx\",\n",
    "    \"desc_col_融資ローン元帳_サンプル.xlsx\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc966de0-5de9-49e6-8425-192b2cdf89dc",
   "metadata": {},
   "source": [
    "## テーブルデータ取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "c38425d6-49a9-48bd-b019-63735d89f499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rename_columns(array):\n",
    "    columns_1 = remove_char_from_array(array, \"−\", \"_\")\n",
    "    columns_2 = remove_char_from_array(columns_1, \"・\", \"_\")\n",
    "    columns_3 = remove_char_from_array(columns_2, \"／\", \"_\")\n",
    "    columns_4 = remove_char_from_array(columns_3, \"（\", \"_\")\n",
    "    columns_5 = remove_char_from_array(columns_4, \"）\", \"\")\n",
    "    return columns_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "203d4d89-569f-454f-b7a4-9f9205500705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_table_data(file_name_list):\n",
    "    table_data_list = []\n",
    "\n",
    "    for file_name in file_name_list:\n",
    "        blob = bucket.blob(f\"{DATASET_DIR}/{file_name}\")\n",
    "        data = blob.download_as_string()\n",
    "\n",
    "        try:\n",
    "            df = pd.read_excel(io.BytesIO(data))\n",
    "            columns = rename_columns(df.columns.values)\n",
    "            df.columns = columns\n",
    "            table_data_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading Excel file: {e}\")\n",
    "            exit(1)\n",
    "            \n",
    "    return table_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "d01a34d1-be76-4966-bbb4-e34ef4f73080",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_data_list = get_table_data(file_name_list=FILE_NAME_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "7f60893c-8505-457f-b0a9-b50070efc413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# table_data_list = []\n",
    "\n",
    "# for file_name in FILE_NAME_LIST:\n",
    "#     blob = bucket.blob(f\"{DATASET_DIR}/{file_name}\")\n",
    "#     data = blob.download_as_string()\n",
    "\n",
    "#     try:\n",
    "#         df = pd.read_excel(io.BytesIO(data))\n",
    "#         columns = rename_columns(df.columns.values)\n",
    "#         df.columns = columns\n",
    "#         table_data_list.append(df)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error reading Excel file: {e}\")\n",
    "#         exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "060594cf-a26d-47db-b4cc-0c6c7dab2bc4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_1218189/1820057242.py:2: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  table_data_list[5][\"銀行コード\"][0] = \"134\"\n",
      "/var/tmp/ipykernel_1218189/1820057242.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  table_data_list[5][\"銀行コード\"][0] = \"134\"\n"
     ]
    }
   ],
   "source": [
    "# ダミーデータ特有の処理\n",
    "if table_data_list[5][\"銀行コード\"][0] != \"134\": \n",
    "    table_data_list[5][\"銀行コード\"][0] = \"134\"\n",
    "    \n",
    "table_data_list[5][\"銀行コード\"] = table_data_list[5][\"銀行コード\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9ac0e3-03fc-438c-856b-cb7ed04295ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## テーブルデータをBigQueryにアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "500b0dab-9edd-4117-a02a-8018b48fe6d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numpy_to_bigquery_type = {\n",
    "    'bool': 'BOOL',\n",
    "    'int8': 'INT64',  \n",
    "    'int16': 'INT64',\n",
    "    'int32': 'INT64',\n",
    "    'int64': 'INT64',\n",
    "    'uint8': 'INT64', \n",
    "    'uint16': 'INT64',\n",
    "    'uint32': 'INT64',\n",
    "    'uint64': 'INT64', \n",
    "    'float16': 'FLOAT64',\n",
    "    'float32': 'FLOAT64',\n",
    "    'float64': 'FLOAT64',\n",
    "    'complex64': 'BIGNUMERIC', \n",
    "    'complex128': 'BIGNUMERIC',\n",
    "    'object': 'STRING', \n",
    "    'datetime64[ns]': 'TIMESTAMP',\n",
    "    'timedelta64[ns]': 'INT64',\n",
    "    'str': 'STRING',\n",
    "    'bytes': 'BYTES'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "dabd8351-cb53-48e9-a9c1-8af31bc3b623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "3e1f08e8-1986-4293-a56b-b5e2448f50e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# カラムdescriptionをファイルからダウンロード\n",
    "def get_column_description(file_name,DESC_COL_DIR = DESC_COL_DIR):\n",
    "    blob = bucket.blob(f\"{DESC_COL_DIR}/{file_name}\")\n",
    "    data = blob.download_as_string()\n",
    "\n",
    "    try:\n",
    "        df_desc_col = pd.read_excel(io.BytesIO(data))\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading Excel file: {e}\")\n",
    "        exit(1)\n",
    "        \n",
    "    return df_desc_col\n",
    "\n",
    "\n",
    "# カラムdescriptionの辞書を作成\n",
    "def create_column_desc_dict(df, column_key=\"項目名称\", column_value=\"コ ー ド\"):\n",
    "    column_desc_dict = {}\n",
    "    column = rename_columns(df[column_key])\n",
    "    column_desc = df[column_value]\n",
    "    \n",
    "    for i in range(len(df[column_key])):\n",
    "        column_desc_dict[column[i]] = column_desc[i]\n",
    "    \n",
    "    for key, value in column_desc_dict.items():\n",
    "        if type(value) == float:\n",
    "            if math.isnan(value):\n",
    "                column_desc_dict[key] = str(' ')\n",
    "                \n",
    "    return column_desc_dict\n",
    "\n",
    "\n",
    "# カラムデータタイプのリスト作成\n",
    "def get_bq_dtype_list(data_list):\n",
    "    column_name_list = data_list.columns.tolist()\n",
    "    dtypes = data_list.dtypes.tolist()\n",
    "\n",
    "    dtype_list = []\n",
    "    for dtype in dtypes:\n",
    "     dtype_list.append(dtype.name)\n",
    "\n",
    "    bq_dtype_list = []\n",
    "    for numpy_type in dtype_list:\n",
    "        bq_dtype = numpy_to_bigquery_type.get(numpy_type)\n",
    "        bq_dtype_list.append(bq_dtype)\n",
    "        \n",
    "    return bq_dtype_list\n",
    "\n",
    "\n",
    "# テーブルスキーマ、テーブルの作成＋データアップロード\n",
    "def create_table(table_id, column_desc_dict, bq_dtype_list):\n",
    "    schema=[]\n",
    "    \n",
    "    for j,key in enumerate(column_desc_dict):\n",
    "        schema.append(SchemaField(key, field_type=bq_dtype_list[j] ,description=column_desc_dict[key]))\n",
    "    try:\n",
    "        table_ref = client.get_table(table_id)\n",
    "        print(f\"Table {table_id} already exists.\")\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            table = bigquery.Table(table_id, schema=schema)\n",
    "            table = client.create_table(table)  \n",
    "            print(f\"Created table {table.project}.{table.dataset_id}.{table.table_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating table: {e}\")\n",
    "            \n",
    "    table_path = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID_LIST[i]}\"\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        autodetect=False,  \n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,  \n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "        schema=schema    \n",
    "    )\n",
    "    try: \n",
    "        job = client.load_table_from_dataframe(\n",
    "            table_data_list[i], table_path, job_config=job_config\n",
    "        ) \n",
    "        job.result() \n",
    "        print(f\"データのアップロードが完了しました。テーブル： {TABLE_ID_LIST[i]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating table: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "b3507811-d6dd-46ef-bccd-c375a1674868",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created table qwiklabs-asl-02-9dacbbe2194b.ASL_dataset4.CIF別取引属性_個人\n",
      "データのアップロードが完了しました。テーブル： CIF別取引属性_個人\n",
      "Created table qwiklabs-asl-02-9dacbbe2194b.ASL_dataset4.CRM_交渉履歴\n",
      "データのアップロードが完了しました。テーブル： CRM_交渉履歴\n",
      "Created table qwiklabs-asl-02-9dacbbe2194b.ASL_dataset4.VISAデビット契約情報\n",
      "データのアップロードが完了しました。テーブル： VISAデビット契約情報\n",
      "Created table qwiklabs-asl-02-9dacbbe2194b.ASL_dataset4.チャネル別利用状況\n",
      "データのアップロードが完了しました。テーブル： チャネル別利用状況\n",
      "Created table qwiklabs-asl-02-9dacbbe2194b.ASL_dataset4.保険元帳\n",
      "データのアップロードが完了しました。テーブル： 保険元帳\n",
      "Created table qwiklabs-asl-02-9dacbbe2194b.ASL_dataset4.入払情報_日次\n",
      "データのアップロードが完了しました。テーブル： 入払情報_日次\n",
      "Created table qwiklabs-asl-02-9dacbbe2194b.ASL_dataset4.名寄せ取引属性_日次\n",
      "データのアップロードが完了しました。テーブル： 名寄せ取引属性_日次\n",
      "Created table qwiklabs-asl-02-9dacbbe2194b.ASL_dataset4.完済融資バッチキー\n",
      "データのアップロードが完了しました。テーブル： 完済融資バッチキー\n",
      "Created table qwiklabs-asl-02-9dacbbe2194b.ASL_dataset4.定期預金元帳\n",
      "データのアップロードが完了しました。テーブル： 定期預金元帳\n",
      "Created table qwiklabs-asl-02-9dacbbe2194b.ASL_dataset4.為替取引明細\n",
      "データのアップロードが完了しました。テーブル： 為替取引明細\n",
      "Created table qwiklabs-asl-02-9dacbbe2194b.ASL_dataset4.融資バッチキー\n",
      "データのアップロードが完了しました。テーブル： 融資バッチキー\n",
      "Created table qwiklabs-asl-02-9dacbbe2194b.ASL_dataset4.融資ローン元帳\n",
      "データのアップロードが完了しました。テーブル： 融資ローン元帳\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(DESC_COL_FILE_NAME_LIST)):\n",
    "    # カラムの説明データの作成\n",
    "    df_desc_col = get_column_description(DESC_COL_FILE_NAME_LIST[i])\n",
    "    column_desc_dict = create_column_desc_dict(df_desc_col)\n",
    "\n",
    "    # カラムデータタイプのリスト作成\n",
    "    bq_dtype_list = get_bq_dtype_list(table_data_list[i])\n",
    "\n",
    "    # テーブル作成\n",
    "    table_id = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID_LIST[i]}\"\n",
    "    create_table(table_id, column_desc_dict, bq_dtype_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6e530cba-7530-490f-9156-12bc69c856a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table CIF別取引属性_個人 already exists.\n",
      "Table CRM_交渉履歴 already exists.\n",
      "Table VISAデビット契約情報 already exists.\n",
      "Table チャネル別利用状況 already exists.\n",
      "Table 保険元帳 already exists.\n",
      "Created table qwiklabs-asl-02-9dacbbe2194b.project.入払情報_日次\n",
      "Table 名寄せ取引属性_日次 already exists.\n",
      "Table 完済融資バッチキー already exists.\n",
      "Table 定期預金元帳 already exists.\n",
      "Table 為替取引明細 already exists.\n",
      "Table 融資バッチキー already exists.\n",
      "Table 融資ローン元帳 already exists.\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(TABLE_ID_LIST)):\n",
    "#     table_id = TABLE_ID_LIST[i]\n",
    "#     desc_col_file_name = f\"{DESC_COL_FOLDER_NAME}.{DESC_COL_FILE_NAME_LIST[i]}\"\n",
    "    \n",
    "#     df_desc_col = get_column_description(desc_col_file_name_list)\n",
    "#     column_desc_dict = create_column_desc_dict(df_desc_col)\n",
    "    \n",
    "#     for key, value in column_desc_dict.items():\n",
    "#         schema = [\"name\"=key, \"description\"=value]\n",
    "#         try:\n",
    "#             table_ref = client.get_table(f\"{PROJECT_ID}.{DATASET_ID}.{table_id}\")\n",
    "#             print(f\"Table {table_id} already exists.\")\n",
    "#         except Exception as e:\n",
    "#             try:\n",
    "#                 table = bigquery.Table(f\"{PROJECT_ID}.{DATASET_ID}.{table_id}\", schema=schema)\n",
    "#                 table = client.create_table(table)  \n",
    "#                 print(f\"Created table {table.project}.{table.dataset_id}.{table.table_id}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error creating table: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "06cc7201-7c20-4554-9265-7efde6e35517",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データのアップロードが完了しました。テーブル： CIF別取引属性_個人\n",
      "データのアップロードが完了しました。テーブル： CRM_交渉履歴\n",
      "データのアップロードが完了しました。テーブル： VISAデビット契約情報\n",
      "データのアップロードが完了しました。テーブル： チャネル別利用状況\n",
      "データのアップロードが完了しました。テーブル： 保険元帳\n",
      "データのアップロードが完了しました。テーブル： 入払情報_日次\n",
      "データのアップロードが完了しました。テーブル： 名寄せ取引属性_日次\n",
      "データのアップロードが完了しました。テーブル： 完済融資バッチキー\n",
      "データのアップロードが完了しました。テーブル： 定期預金元帳\n",
      "データのアップロードが完了しました。テーブル： 為替取引明細\n",
      "データのアップロードが完了しました。テーブル： 融資バッチキー\n",
      "データのアップロードが完了しました。テーブル： 融資ローン元帳\n"
     ]
    }
   ],
   "source": [
    "# for i in range(len(TABLE_ID_LIST)):\n",
    "#     table_path = f\"{PROJECT_ID}.{DATASET_ID}.{TABLE_ID_LIST[i]}\"\n",
    "#     job_config = bigquery.LoadJobConfig(\n",
    "#     autodetect=False,  \n",
    "#     write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,  \n",
    "#     source_format=bigquery.SourceFormat.CSV, \n",
    "#     )\n",
    "#     try: \n",
    "#         job = client.load_table_from_dataframe(\n",
    "#             table_data_list[i], table_path, job_config=job_config\n",
    "#         ) \n",
    "#         job.result() \n",
    "#         print(f\"データのアップロードが完了しました。テーブル： {TABLE_ID_LIST[i]}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error creating table: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abd1803-671f-4c37-8330-e833ce1ebc6e",
   "metadata": {},
   "source": [
    "## カラムdescriptionの追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "7cd51650-9c62-409e-b42e-76767d970dc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute 'description'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[358], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m new_schema \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m table_ref\u001b[38;5;241m.\u001b[39mschema:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mfield\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdescription\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m     field\u001b[38;5;241m.\u001b[39mdescription \u001b[38;5;241m=\u001b[39m column_desc_dict\u001b[38;5;241m.\u001b[39mget(field\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     new_schema.append(field)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# table_ref.schema = new_schema\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print(f\"Table {table_ref.reference} updated successfully.\")\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute 'description'"
     ]
    }
   ],
   "source": [
    "# client = bigquery.Client()\n",
    "# table_ref = client.get_table(f\"{DATASET_ID}.{TABLE_ID_LIST[0]}\")\n",
    "\n",
    "# new_schema = []\n",
    "# for field in table_ref.schema:\n",
    "#     field.description = 'test'\n",
    "#     field.description = column_desc_dict.get(field.name)\n",
    "#     new_schema.append(field)\n",
    "\n",
    "# table_ref.schema = new_schema\n",
    "\n",
    "# # テーブルを更新\n",
    "# table = client.update_table(table_ref, [\"schema\"])  # 更新する属性を指定\n",
    "\n",
    "# print(f\"Table {table_ref.reference} updated successfully.\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
